# -*- coding: utf-8 -*-
"""Cyber_Security_Attack_Detection_Using_Xgboost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mHNbX0x_AXS_zov3lgGT5nzosFNf70uS
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # Importation de la bibliothèque NumPy pour effectuer des calculs numériques.
import pandas as pd # Importation de la bibliothèque pandas pour manipuler les données sous forme de DataFrame.
import warnings # Importation du module warnings pour gérer les avertissements.
import matplotlib.pyplot as plt # Importation de la bibliothèque Matplotlib pour tracer des graphiques.
import seaborn as sns # Importation de la bibliothèque Seaborn pour créer des visualisations attrayantes.
import tensorflow as tf # Importation de la bibliothèque TensorFlow pour l'apprentissage automatique.
from tensorflow.keras import regularizers # Importation des régularisateurs de TensorFlow Keras.
import xgboost as xgb # Importation de la bibliothèque XGBoost pour les modèles de renforcement de gradient.
from sklearn.decomposition import PCA # Importation de la classe PCA de scikit-learn pour l'analyse en composantes principales.
from sklearn import tree # Importation des algorithmes d'arbre de décision de scikit-learn.
from sklearn.naive_bayes import GaussianNB # Importation du classificateur naïf bayésien gaussien de scikit-learn.
from sklearn.linear_model import LogisticRegression # Importation de la régression logistique de scikit-learn.
from sklearn.neighbors import KNeighborsClassifier # Importation du classificateur des k plus proches voisins de scikit-learn.
from sklearn.tree import DecisionTreeClassifier # Importation du classificateur arbre de décision de scikit-learn.
from sklearn.preprocessing import RobustScaler # Importation de la classe RobustScaler de scikit-learn pour la mise à l'échelle des données.
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor # Importation des classificateurs et régresseurs RandomForest de scikit-learn.
from sklearn.model_selection import train_test_split # Importation de la fonction train_test_split de scikit-learn pour diviser les données en ensembles d'entraînement et de test.
from sklearn import svm # Importation de la machine à vecteurs de support (SVM) de scikit-learn.
from sklearn import metrics # Importation des métriques de scikit-learn pour évaluer les performances des modèles.
pd.set_option('display.max_columns', None) # Configuration de pandas pour afficher toutes les colonnes des DataFrames.
warnings.filterwarnings('ignore') # Ignorer les avertissements.
# %matplotlib inline

# Read Train and Test dataset
data_train = pd.read_csv("/content/KDDTrain+.txt")
# Check data
data_train.head()

columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot'
,'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations'
,'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate'
,'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'
,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate'
,'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','outcome','level'])

# Assign name for columns
data_train.columns = columns

data_train.head()

#Afficher les informations sur le jeu de données d'entraînement
data_train.info()

#Afficher les statistiques descriptives du jeu de données d'entraînement
data_train.describe().style.background_gradient(cmap='Blues').set_properties(**{'font-family':'Segoe UI'})

#Remplacement les valeurs dans la colonne 'outcome'
data_train.loc[data_train['outcome'] == "normal", "outcome"] = 'normal'
data_train.loc[data_train['outcome'] != 'normal', "outcome"] = 'attack'

#Fonction pour tracer un diagramme circulaire (camembert)
def pie_plot(df, cols_list, rows, cols):
    fig, axes = plt.subplots(rows, cols)
    for ax, col in zip(axes.ravel(), cols_list):
        df[col].value_counts().plot(ax=ax, kind='pie', figsize=(15, 15), fontsize=10, autopct='%1.0f%%')
        ax.set_title(str(col), fontsize = 12)
    plt.show()

pie_plot(data_train, ['protocol_type', 'outcome'], 1, 2)

# Fonction pour effectuer une mise à l'échelle des données numériques
def Scaling(df_num, cols):
    std_scaler = RobustScaler()
    std_scaler_temp = std_scaler.fit_transform(df_num)
    std_df = pd.DataFrame(std_scaler_temp, columns =cols)
    return std_df

cat_cols = ['is_host_login','protocol_type','service','flag','land', 'logged_in','is_guest_login', 'level', 'outcome']
def preprocess(dataframe):
    df_num = dataframe.drop(cat_cols, axis=1)
    num_cols = df_num.columns
    scaled_df = Scaling(df_num, num_cols)

    dataframe.drop(labels=num_cols, axis="columns", inplace=True)
    dataframe[num_cols] = scaled_df[num_cols]

    dataframe.loc[dataframe['outcome'] == "normal", "outcome"] = 0
    dataframe.loc[dataframe['outcome'] != 0, "outcome"] = 1

    dataframe = pd.get_dummies(dataframe, columns = ['protocol_type', 'service', 'flag'])
    return dataframe

# Prétraitement des données d'entraînement
scaled_train = preprocess(data_train)

x = scaled_train.drop(['outcome', 'level'], axis=1).values
y = scaled_train['outcome'].values
y_reg = scaled_train['level'].values

# Sélection des variables prédictives en excluant les colonnes 'outcome' et 'level' du DataFrame "scaled_train"
x = scaled_train.drop(['outcome', 'level'], axis=1).values

# Extraction de la variable cible 'outcome' dans "y"
y = scaled_train['outcome'].values

# Extraction de la variable cible de régression 'level' dans "y_reg"
y_reg = scaled_train['level'].values

# Réduction de dimension avec PCA
pca = PCA(n_components=20)
pca = pca.fit(x)
x_reduced = pca.transform(x)

# Affichage du nombre de caractéristiques originales et réduites après PCA
print("Le nombre de caractéristiques originales est {} et le nombre de caractéristiques réduites est {}".format(x.shape[1], x_reduced.shape[1]))

# Conversion du type de la variable cible "y" en entier
y = y.astype('int')

# Séparation des données en ensembles d'entraînement et de test pour la classification
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Séparation des données réduites en ensembles d'entraînement et de test pour la classification
x_train_reduced, x_test_reduced, y_train_reduced, y_test_reduced = train_test_split(x_reduced, y, test_size=0.2, random_state=42)

# Séparation des données en ensembles d'entraînement et de test pour la régression
x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x, y_reg, test_size=0.2, random_state=42)

kernal_evals = dict()
def evaluate_classification(model, name, X_train, X_test, y_train, y_test):
    train_accuracy = metrics.accuracy_score(y_train, model.predict(X_train))
    test_accuracy = metrics.accuracy_score(y_test, model.predict(X_test))

    train_precision = metrics.precision_score(y_train, model.predict(X_train))
    test_precision = metrics.precision_score(y_test, model.predict(X_test))

    train_recall = metrics.recall_score(y_train, model.predict(X_train))
    test_recall = metrics.recall_score(y_test, model.predict(X_test))

    kernal_evals[str(name)] = [train_accuracy, test_accuracy, train_precision, test_precision, train_recall, test_recall]
    print("Training Accuracy " + str(name) + " {}  Test Accuracy ".format(train_accuracy*100) + str(name) + " {}".format(test_accuracy*100))
    print("Training Precesion " + str(name) + " {}  Test Precesion ".format(train_precision*100) + str(name) + " {}".format(test_precision*100))
    print("Training Recall " + str(name) + " {}  Test Recall ".format(train_recall*100) + str(name) + " {}".format(test_recall*100))

    actual = y_test
    predicted = model.predict(X_test)
    confusion_matrix = metrics.confusion_matrix(actual, predicted)
    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['normal', 'attack'])

    fig, ax = plt.subplots(figsize=(10,10))
    ax.grid(False)
    cm_display.plot(ax=ax)

import xgboost as xgb

# Train the XGBoost classifier
xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, random_state=42)
xgb_classifier.fit(x_train, y_train)

# Evaluate the XGBoost classifier
evaluate_classification(xgb_classifier, "XGBoost", x_train, x_test, y_train, y_test)





